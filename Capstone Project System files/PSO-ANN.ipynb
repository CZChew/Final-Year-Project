{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPSTONE PROJECT: phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimization training Artificial Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs forward pass during Neural Net training.\n",
    "    :param X: double(N, F)\n",
    "        X is input where N is number of instances and F is number of features.\n",
    "    :param Y: int(N, ) | int(N, C)\n",
    "        Y is target where N is number of instances and C is number of classes in case of\n",
    "        one-hot encoded target.\n",
    "    :param W: double(N, )\n",
    "        Weights where N is number of total weights(flatten).\n",
    "    :return: double\n",
    "        Returns loss of forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.5.3\n",
      "numpy: 1.23.5\n",
      "sklearn: 1.2.1\n",
      "pyswarms: 1.3.0\n",
      "plotly: 5.9.0\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "# Sklearn\n",
    "import sklearn # for model evaluation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "#from sklearn.model_selection import train_test_split # for splitting data into train and test samples\n",
    "#from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "from psopy import *\n",
    "import pyswarms as ps\n",
    "print('pyswarms: %s' % ps.__version__)\n",
    "\n",
    "# Visualization\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "print('plotly: %s' % plotly.__version__) # print version\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBDIVISION</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUN</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AUG</th>\n",
       "      <th>SEP</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DEC</th>\n",
       "      <th>ANNUAL RAINFALL</th>\n",
       "      <th>FLOODS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1901</td>\n",
       "      <td>28.7</td>\n",
       "      <td>44.7</td>\n",
       "      <td>51.6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>174.7</td>\n",
       "      <td>824.6</td>\n",
       "      <td>743.0</td>\n",
       "      <td>357.5</td>\n",
       "      <td>197.7</td>\n",
       "      <td>266.9</td>\n",
       "      <td>350.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>3248.6</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1902</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>57.3</td>\n",
       "      <td>83.9</td>\n",
       "      <td>134.5</td>\n",
       "      <td>390.9</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>315.8</td>\n",
       "      <td>491.6</td>\n",
       "      <td>358.4</td>\n",
       "      <td>158.3</td>\n",
       "      <td>121.5</td>\n",
       "      <td>3326.6</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1903</td>\n",
       "      <td>3.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>83.6</td>\n",
       "      <td>249.7</td>\n",
       "      <td>558.6</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>420.2</td>\n",
       "      <td>341.8</td>\n",
       "      <td>354.1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3271.2</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1904</td>\n",
       "      <td>23.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>71.5</td>\n",
       "      <td>235.7</td>\n",
       "      <td>1098.2</td>\n",
       "      <td>725.5</td>\n",
       "      <td>351.8</td>\n",
       "      <td>222.7</td>\n",
       "      <td>328.1</td>\n",
       "      <td>33.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3129.7</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>105.9</td>\n",
       "      <td>263.3</td>\n",
       "      <td>850.2</td>\n",
       "      <td>520.5</td>\n",
       "      <td>293.6</td>\n",
       "      <td>217.2</td>\n",
       "      <td>383.5</td>\n",
       "      <td>74.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2741.6</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.3</td>\n",
       "      <td>17.9</td>\n",
       "      <td>95.7</td>\n",
       "      <td>251.0</td>\n",
       "      <td>454.4</td>\n",
       "      <td>677.8</td>\n",
       "      <td>733.9</td>\n",
       "      <td>298.8</td>\n",
       "      <td>355.5</td>\n",
       "      <td>99.5</td>\n",
       "      <td>47.2</td>\n",
       "      <td>3046.4</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>50.1</td>\n",
       "      <td>214.1</td>\n",
       "      <td>201.8</td>\n",
       "      <td>563.6</td>\n",
       "      <td>406.0</td>\n",
       "      <td>252.2</td>\n",
       "      <td>292.9</td>\n",
       "      <td>308.1</td>\n",
       "      <td>223.6</td>\n",
       "      <td>79.4</td>\n",
       "      <td>2600.6</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>35.9</td>\n",
       "      <td>143.0</td>\n",
       "      <td>186.4</td>\n",
       "      <td>522.2</td>\n",
       "      <td>412.3</td>\n",
       "      <td>325.5</td>\n",
       "      <td>173.2</td>\n",
       "      <td>225.9</td>\n",
       "      <td>125.4</td>\n",
       "      <td>23.6</td>\n",
       "      <td>2176.6</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>43.6</td>\n",
       "      <td>173.5</td>\n",
       "      <td>498.5</td>\n",
       "      <td>319.6</td>\n",
       "      <td>531.8</td>\n",
       "      <td>209.5</td>\n",
       "      <td>192.4</td>\n",
       "      <td>92.5</td>\n",
       "      <td>38.1</td>\n",
       "      <td>2117.1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2018</td>\n",
       "      <td>29.1</td>\n",
       "      <td>52.1</td>\n",
       "      <td>48.6</td>\n",
       "      <td>116.4</td>\n",
       "      <td>183.8</td>\n",
       "      <td>625.4</td>\n",
       "      <td>1048.5</td>\n",
       "      <td>1398.9</td>\n",
       "      <td>423.6</td>\n",
       "      <td>356.1</td>\n",
       "      <td>125.4</td>\n",
       "      <td>65.1</td>\n",
       "      <td>4473.0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBDIVISION  YEAR   JAN   FEB   MAR    APR    MAY     JUN     JUL     AUG  \\\n",
       "0        KERALA  1901  28.7  44.7  51.6  160.0  174.7   824.6   743.0   357.5   \n",
       "1        KERALA  1902   6.7   2.6  57.3   83.9  134.5   390.9  1205.0   315.8   \n",
       "2        KERALA  1903   3.2  18.6   3.1   83.6  249.7   558.6  1022.5   420.2   \n",
       "3        KERALA  1904  23.7   3.0  32.2   71.5  235.7  1098.2   725.5   351.8   \n",
       "4        KERALA  1905   1.2  22.3   9.4  105.9  263.3   850.2   520.5   293.6   \n",
       "..          ...   ...   ...   ...   ...    ...    ...     ...     ...     ...   \n",
       "113      KERALA  2014   4.6  10.3  17.9   95.7  251.0   454.4   677.8   733.9   \n",
       "114      KERALA  2015   3.1   5.8  50.1  214.1  201.8   563.6   406.0   252.2   \n",
       "115      KERALA  2016   2.4   3.8  35.9  143.0  186.4   522.2   412.3   325.5   \n",
       "116     KERALA   2017   1.9   6.8   8.9   43.6  173.5   498.5   319.6   531.8   \n",
       "117      KERALA  2018  29.1  52.1  48.6  116.4  183.8   625.4  1048.5  1398.9   \n",
       "\n",
       "       SEP    OCT    NOV    DEC   ANNUAL RAINFALL FLOODS  \n",
       "0    197.7  266.9  350.8   48.4            3248.6    YES  \n",
       "1    491.6  358.4  158.3  121.5            3326.6    YES  \n",
       "2    341.8  354.1  157.0   59.0            3271.2    YES  \n",
       "3    222.7  328.1   33.9    3.3            3129.7    YES  \n",
       "4    217.2  383.5   74.4    0.2            2741.6     NO  \n",
       "..     ...    ...    ...    ...               ...    ...  \n",
       "113  298.8  355.5   99.5   47.2            3046.4    YES  \n",
       "114  292.9  308.1  223.6   79.4            2600.6     NO  \n",
       "115  173.2  225.9  125.4   23.6            2176.6     NO  \n",
       "116  209.5  192.4   92.5   38.1            2117.1     NO  \n",
       "117  423.6  356.1  125.4   65.1            4473.0    YES  \n",
       "\n",
       "[118 rows x 16 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset of Kerala\n",
    "data=pd.read_csv('kerala.csv', encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBDIVISION</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>JAN</th>\n",
       "      <th>FEB</th>\n",
       "      <th>MAR</th>\n",
       "      <th>APR</th>\n",
       "      <th>MAY</th>\n",
       "      <th>JUN</th>\n",
       "      <th>JUL</th>\n",
       "      <th>AUG</th>\n",
       "      <th>SEP</th>\n",
       "      <th>OCT</th>\n",
       "      <th>NOV</th>\n",
       "      <th>DEC</th>\n",
       "      <th>ANNUAL RAINFALL</th>\n",
       "      <th>FLOODS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1901</td>\n",
       "      <td>28.7</td>\n",
       "      <td>44.7</td>\n",
       "      <td>51.6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>174.7</td>\n",
       "      <td>824.6</td>\n",
       "      <td>743.0</td>\n",
       "      <td>357.5</td>\n",
       "      <td>197.7</td>\n",
       "      <td>266.9</td>\n",
       "      <td>350.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>3248.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1902</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>57.3</td>\n",
       "      <td>83.9</td>\n",
       "      <td>134.5</td>\n",
       "      <td>390.9</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>315.8</td>\n",
       "      <td>491.6</td>\n",
       "      <td>358.4</td>\n",
       "      <td>158.3</td>\n",
       "      <td>121.5</td>\n",
       "      <td>3326.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1903</td>\n",
       "      <td>3.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>83.6</td>\n",
       "      <td>249.7</td>\n",
       "      <td>558.6</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>420.2</td>\n",
       "      <td>341.8</td>\n",
       "      <td>354.1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3271.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1904</td>\n",
       "      <td>23.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>71.5</td>\n",
       "      <td>235.7</td>\n",
       "      <td>1098.2</td>\n",
       "      <td>725.5</td>\n",
       "      <td>351.8</td>\n",
       "      <td>222.7</td>\n",
       "      <td>328.1</td>\n",
       "      <td>33.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3129.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>105.9</td>\n",
       "      <td>263.3</td>\n",
       "      <td>850.2</td>\n",
       "      <td>520.5</td>\n",
       "      <td>293.6</td>\n",
       "      <td>217.2</td>\n",
       "      <td>383.5</td>\n",
       "      <td>74.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2741.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.3</td>\n",
       "      <td>17.9</td>\n",
       "      <td>95.7</td>\n",
       "      <td>251.0</td>\n",
       "      <td>454.4</td>\n",
       "      <td>677.8</td>\n",
       "      <td>733.9</td>\n",
       "      <td>298.8</td>\n",
       "      <td>355.5</td>\n",
       "      <td>99.5</td>\n",
       "      <td>47.2</td>\n",
       "      <td>3046.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>50.1</td>\n",
       "      <td>214.1</td>\n",
       "      <td>201.8</td>\n",
       "      <td>563.6</td>\n",
       "      <td>406.0</td>\n",
       "      <td>252.2</td>\n",
       "      <td>292.9</td>\n",
       "      <td>308.1</td>\n",
       "      <td>223.6</td>\n",
       "      <td>79.4</td>\n",
       "      <td>2600.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>35.9</td>\n",
       "      <td>143.0</td>\n",
       "      <td>186.4</td>\n",
       "      <td>522.2</td>\n",
       "      <td>412.3</td>\n",
       "      <td>325.5</td>\n",
       "      <td>173.2</td>\n",
       "      <td>225.9</td>\n",
       "      <td>125.4</td>\n",
       "      <td>23.6</td>\n",
       "      <td>2176.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>43.6</td>\n",
       "      <td>173.5</td>\n",
       "      <td>498.5</td>\n",
       "      <td>319.6</td>\n",
       "      <td>531.8</td>\n",
       "      <td>209.5</td>\n",
       "      <td>192.4</td>\n",
       "      <td>92.5</td>\n",
       "      <td>38.1</td>\n",
       "      <td>2117.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>KERALA</td>\n",
       "      <td>2018</td>\n",
       "      <td>29.1</td>\n",
       "      <td>52.1</td>\n",
       "      <td>48.6</td>\n",
       "      <td>116.4</td>\n",
       "      <td>183.8</td>\n",
       "      <td>625.4</td>\n",
       "      <td>1048.5</td>\n",
       "      <td>1398.9</td>\n",
       "      <td>423.6</td>\n",
       "      <td>356.1</td>\n",
       "      <td>125.4</td>\n",
       "      <td>65.1</td>\n",
       "      <td>4473.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBDIVISION  YEAR   JAN   FEB   MAR    APR    MAY     JUN     JUL     AUG  \\\n",
       "0        KERALA  1901  28.7  44.7  51.6  160.0  174.7   824.6   743.0   357.5   \n",
       "1        KERALA  1902   6.7   2.6  57.3   83.9  134.5   390.9  1205.0   315.8   \n",
       "2        KERALA  1903   3.2  18.6   3.1   83.6  249.7   558.6  1022.5   420.2   \n",
       "3        KERALA  1904  23.7   3.0  32.2   71.5  235.7  1098.2   725.5   351.8   \n",
       "4        KERALA  1905   1.2  22.3   9.4  105.9  263.3   850.2   520.5   293.6   \n",
       "..          ...   ...   ...   ...   ...    ...    ...     ...     ...     ...   \n",
       "113      KERALA  2014   4.6  10.3  17.9   95.7  251.0   454.4   677.8   733.9   \n",
       "114      KERALA  2015   3.1   5.8  50.1  214.1  201.8   563.6   406.0   252.2   \n",
       "115      KERALA  2016   2.4   3.8  35.9  143.0  186.4   522.2   412.3   325.5   \n",
       "116     KERALA   2017   1.9   6.8   8.9   43.6  173.5   498.5   319.6   531.8   \n",
       "117      KERALA  2018  29.1  52.1  48.6  116.4  183.8   625.4  1048.5  1398.9   \n",
       "\n",
       "       SEP    OCT    NOV    DEC   ANNUAL RAINFALL  FLOODS  \n",
       "0    197.7  266.9  350.8   48.4            3248.6       1  \n",
       "1    491.6  358.4  158.3  121.5            3326.6       1  \n",
       "2    341.8  354.1  157.0   59.0            3271.2       1  \n",
       "3    222.7  328.1   33.9    3.3            3129.7       1  \n",
       "4    217.2  383.5   74.4    0.2            2741.6       0  \n",
       "..     ...    ...    ...    ...               ...     ...  \n",
       "113  298.8  355.5   99.5   47.2            3046.4       1  \n",
       "114  292.9  308.1  223.6   79.4            2600.6       0  \n",
       "115  173.2  225.9  125.4   23.6            2176.6       0  \n",
       "116  209.5  192.4   92.5   38.1            2117.1       0  \n",
       "117  423.6  356.1  125.4   65.1            4473.0       1  \n",
       "\n",
       "[118 rows x 16 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['FLOODS'].replace(['YES','NO'],[1,0],inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUBDIVISION\n",
       "KERALA     117\n",
       "KERALA       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('SUBDIVISION').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the data \n",
    "data = data.rename(columns={' ANNUAL RAINFALL': 'ANNUAL'})\n",
    "data = data.iloc[2:15]\n",
    "\n",
    "# Store input & target in X and Y..\n",
    "X = data[['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC','ANNUAL']]\n",
    "#X = data[['OCT','NOV','DEC','ANNUAL']]\n",
    "Y = data[['FLOODS']]\n",
    "\n",
    "# Normalize the input features\n",
    "scaler = MinMaxScaler()\n",
    "X = X.values.reshape(-1,13) \n",
    "Y = Y.values.reshape(1,13) \n",
    "\n",
    "# ANN structure model\n",
    "\"\"\"\n",
    "The values represents the number of nodes in the layers\n",
    "\"\"\"\n",
    "INPUT_LAYER = 13\n",
    "HIDDEN_LAYER = 2\n",
    "OUTPUT_LAYER = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a PSO(interia weight) variation...\n",
    "class Particle:\n",
    "    \"\"\"\n",
    "    Particle class represents a solution inside a pool(Swarm).\n",
    "    no_dim = number of dimension\n",
    "    x_range = range of search space\n",
    "    v_range = range of velocity in each dimension\n",
    "    \"\"\"\n",
    "    def __init__(self, no_dim, x_range, v_range):\n",
    "        self.x = np.random.uniform(\n",
    "            x_range[0], x_range[1], (no_dim,)\n",
    "        )  # particle position in each dimension...\n",
    "        self.v = np.random.uniform(\n",
    "            v_range[0], v_range[1], (no_dim,)\n",
    "        )  # particle velocity in each dimension...\n",
    "        self.pbest = np.inf\n",
    "        self.pbestpos = np.zeros((no_dim,))\n",
    "\n",
    "class Swarm:\n",
    "    \"\"\"\n",
    "    Swarm class represents a pool of solution(particle).\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, no_particle, no_dim, x_range, v_range, iw_range, c):\n",
    "        self.p = np.array(\n",
    "            [Particle(no_dim, x_range, v_range) for i in range(no_particle)]\n",
    "        )\n",
    "        self.gbest = np.inf\n",
    "        self.gbestpos = np.zeros((no_dim,))\n",
    "        self.x_range = x_range\n",
    "        self.v_range = v_range\n",
    "        self.iw_range = iw_range\n",
    "        self.c0 = c[0]\n",
    "        self.c1 = c[1]\n",
    "        self.no_dim = no_dim\n",
    "\n",
    "    def optimize(self, function, X, Y, print_step, iter):\n",
    "        for i in range(iter):\n",
    "            for particle in self.p:\n",
    "                fitness = function(X, Y, particle.x)\n",
    "\n",
    "                if fitness < particle.pbest:\n",
    "                    particle.pbest = fitness\n",
    "                    particle.pbestpos = particle.x.copy()\n",
    "\n",
    "                if fitness < self.gbest:\n",
    "                    self.gbest = fitness\n",
    "                    self.gbestpos = particle.x.copy()\n",
    "\n",
    "            for particle in self.p:\n",
    "                # Here iw is inertia weight\n",
    "                iw = np.random.uniform(self.iw_range[0], self.iw_range[1], 1)[0]\n",
    "                particle.v = (\n",
    "                    iw * particle.v\n",
    "                    + (\n",
    "                        self.c0\n",
    "                        * np.random.uniform(0.0, 1.0, (self.no_dim,))\n",
    "                        * (particle.pbestpos - particle.x)\n",
    "                    )\n",
    "                    + (\n",
    "                        self.c1\n",
    "                        * np.random.uniform(0.0, 1.0, (self.no_dim,))\n",
    "                        * (self.gbestpos - particle.x)\n",
    "                    )\n",
    "                )\n",
    "                particle.x = particle.x + particle.v           \n",
    "\n",
    "            if i % print_step == 0:\n",
    "                print(\"iteration#: \", i + 1, \" loss: \", fitness)\n",
    "\n",
    "        print(\"global best loss: \", self.gbest)\n",
    "\n",
    "    def get_best_solution(self):\n",
    "        \"\"\"\n",
    "        :return: array of parameters/weights.\n",
    "        function used after optimized function to get the best solution found by PSO\n",
    "        \"\"\"\n",
    "        return self.gbestpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(Y):\n",
    "    num_unique = len(np.unique(np.array(Y)))\n",
    "    zeros = np.zeros((len(Y), num_unique))\n",
    "    zeros[range(len(Y)), Y] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    \"\"\"\"\n",
    "    The softmax function is to calculate the probability of each class from the logits where some of them are equal to 1\n",
    "    logits refers to the output of the last layer without any activation applied\n",
    "    \"\"\"\n",
    "    exps = np.exp(logits)\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Negative_Likelihood(probs, Y):\n",
    "    num_samples = len(probs)\n",
    "    correct_logprobs = -np.log(probs[range(num_samples), Y])\n",
    "    return np.sum(correct_logprobs) / num_samples\n",
    "\n",
    "def Cross_Entropy(probs, Y):\n",
    "    num_samples = len(probs)\n",
    "    ind_loss = np.max(-1 * Y * np.log(probs + 1e-12), axis=1)\n",
    "    return np.sum(ind_loss) / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, Y, W): # training forward pass\n",
    "    if isinstance(W, Particle):\n",
    "        W = W.x\n",
    "\n",
    "    w1 = W[0 : INPUT_LAYER * HIDDEN_LAYER].reshape((INPUT_LAYER, HIDDEN_LAYER))\n",
    "    b1 = W[INPUT_LAYER * HIDDEN_LAYER:(INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER].reshape((HIDDEN_LAYER, ))\n",
    "    w2 = W[(INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER:(INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER +\\\n",
    "        (HIDDEN_LAYER * OUTPUT_LAYER)].reshape((HIDDEN_LAYER, OUTPUT_LAYER))\n",
    "    b2 = W[(INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER + (HIDDEN_LAYER * OUTPUT_LAYER): (INPUT_LAYER *\\\n",
    "        HIDDEN_LAYER) + HIDDEN_LAYER + (HIDDEN_LAYER * OUTPUT_LAYER) + OUTPUT_LAYER].reshape((OUTPUT_LAYER, ))\n",
    "\n",
    "    z1 = np.dot(X, w1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = np.dot(a1, w2) + b2\n",
    "    logits = z2\n",
    "\n",
    "    probs = softmax(logits)\n",
    "    return Negative_Likelihood(probs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W):\n",
    "    \"\"\"\n",
    "    Performs forward pass during Neural Net test.\n",
    "    Takes X(input data) and W(trained weights after PSO training completion)\n",
    "    \"\"\"\n",
    "    w1 = W[0: INPUT_LAYER * HIDDEN_LAYER].reshape((INPUT_LAYER, HIDDEN_LAYER))\n",
    "    b1 = W[INPUT_LAYER * HIDDEN_LAYER:(INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER].reshape((HIDDEN_LAYER,))\n",
    "    w2 = W[(INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER:(INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER + \\\n",
    "        (HIDDEN_LAYER * OUTPUT_LAYER)].reshape((HIDDEN_LAYER, OUTPUT_LAYER))\n",
    "    b2 = W[(INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER + (HIDDEN_LAYER * OUTPUT_LAYER): (INPUT_LAYER * \\\n",
    "        HIDDEN_LAYER) + HIDDEN_LAYER + (HIDDEN_LAYER * OUTPUT_LAYER) + OUTPUT_LAYER].reshape((OUTPUT_LAYER,))\n",
    "\n",
    "    z1 = np.dot(X, w1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = np.dot(a1, w2) + b2\n",
    "    logits = z2\n",
    "    probs = softmax(logits)\n",
    "    Y_pred =  np.argmax(probs, axis=1)\n",
    "    \n",
    "    return Y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(Y, Y_pred):\n",
    "    return (Y == Y_pred).mean()\n",
    "\n",
    "# calculates accuracy of TEST data with actual and predicted labels.\n",
    "# takes Y(actual labels) and Y_pred(predicted labels) then count all the true prediction and .mean it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration#:  1  loss:  0.7265292721921486\n",
      "iteration#:  11  loss:  0.7560073235415984\n",
      "iteration#:  21  loss:  0.9397565672742846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration#:  31  loss:  0.7034365756862405\n",
      "iteration#:  41  loss:  0.8850451112651428\n",
      "iteration#:  51  loss:  0.8103952198277689\n",
      "iteration#:  61  loss:  0.6933055561367388\n",
      "iteration#:  71  loss:  1.0594549346336666\n",
      "iteration#:  81  loss:  0.9017598573466632\n",
      "iteration#:  91  loss:  1.0706477007460475\n",
      "iteration#:  101  loss:  0.6905587134268472\n",
      "iteration#:  111  loss:  1.1424531686463637\n",
      "iteration#:  121  loss:  1.2580623928123933\n",
      "iteration#:  131  loss:  0.7821496240351292\n",
      "iteration#:  141  loss:  0.6959937724319172\n",
      "iteration#:  151  loss:  0.7812559521064094\n",
      "iteration#:  161  loss:  1.9807066213519595\n",
      "iteration#:  171  loss:  3.1890024218247435\n",
      "iteration#:  181  loss:  2.778271724024921\n",
      "iteration#:  191  loss:  1.7611130090706761\n",
      "iteration#:  201  loss:  1.5830567187690008\n",
      "iteration#:  211  loss:  1.369959486164076\n",
      "iteration#:  221  loss:  1.4221731515329568\n",
      "iteration#:  231  loss:  0.861891048153749\n",
      "iteration#:  241  loss:  0.9346614810977198\n",
      "iteration#:  251  loss:  0.9362165020158153\n",
      "iteration#:  261  loss:  1.2482551298006088\n",
      "iteration#:  271  loss:  0.773307987492764\n",
      "iteration#:  281  loss:  1.04653999752997\n",
      "iteration#:  291  loss:  0.759470909252941\n",
      "iteration#:  301  loss:  0.8709247616892116\n",
      "iteration#:  311  loss:  0.735718832636032\n",
      "iteration#:  321  loss:  0.7084595204291931\n",
      "iteration#:  331  loss:  0.9835901207481997\n",
      "iteration#:  341  loss:  1.0066232990027997\n",
      "iteration#:  351  loss:  1.573127045275381\n",
      "iteration#:  361  loss:  0.6950198729786974\n",
      "iteration#:  371  loss:  0.7586639049004632\n",
      "iteration#:  381  loss:  0.77128369483967\n",
      "iteration#:  391  loss:  1.0409435534790936\n",
      "iteration#:  401  loss:  0.9617542734617396\n",
      "iteration#:  411  loss:  1.7297164282876252\n",
      "iteration#:  421  loss:  1.0588919322542987\n",
      "iteration#:  431  loss:  0.7034097990604149\n",
      "iteration#:  441  loss:  1.3364421185728808\n",
      "iteration#:  451  loss:  0.6959124807568243\n",
      "iteration#:  461  loss:  0.7617143020868864\n",
      "iteration#:  471  loss:  0.8007546289316861\n",
      "iteration#:  481  loss:  0.8242649940351401\n",
      "iteration#:  491  loss:  1.4480494777269706\n",
      "iteration#:  501  loss:  0.9383557742703419\n",
      "iteration#:  511  loss:  1.085631246103945\n",
      "iteration#:  521  loss:  0.96270540027737\n",
      "iteration#:  531  loss:  0.7646974579882541\n",
      "iteration#:  541  loss:  0.731299293795683\n",
      "iteration#:  551  loss:  0.9190427224657308\n",
      "iteration#:  561  loss:  2.009070707666395\n",
      "iteration#:  571  loss:  1.4234278876739348\n",
      "iteration#:  581  loss:  1.7003995432417556\n",
      "iteration#:  591  loss:  3.2472907313929436\n",
      "iteration#:  601  loss:  2.0388736724917673\n",
      "iteration#:  611  loss:  0.7089526753054136\n",
      "iteration#:  621  loss:  0.6915134880606406\n",
      "iteration#:  631  loss:  0.7039075855566008\n",
      "iteration#:  641  loss:  0.8752806729499341\n",
      "iteration#:  651  loss:  0.690609978365683\n",
      "iteration#:  661  loss:  1.3789914186616619\n",
      "iteration#:  671  loss:  0.8621647629747178\n",
      "iteration#:  681  loss:  0.9495568611059488\n",
      "iteration#:  691  loss:  1.1972273373797224\n",
      "iteration#:  701  loss:  0.6981868693657542\n",
      "iteration#:  711  loss:  0.7525311245950519\n",
      "iteration#:  721  loss:  0.7051456584229696\n",
      "iteration#:  731  loss:  0.7248648464902361\n",
      "iteration#:  741  loss:  1.8887914486926707\n",
      "iteration#:  751  loss:  1.057195666335945\n",
      "iteration#:  761  loss:  0.7385964267778082\n",
      "iteration#:  771  loss:  0.7343961004793047\n",
      "iteration#:  781  loss:  1.0362920071392403\n",
      "iteration#:  791  loss:  0.7231581329536441\n",
      "iteration#:  801  loss:  0.7028601004439016\n",
      "iteration#:  811  loss:  1.405218791799943\n",
      "iteration#:  821  loss:  0.7718369209829425\n",
      "iteration#:  831  loss:  0.6919313458549343\n",
      "iteration#:  841  loss:  0.7005038395353331\n",
      "iteration#:  851  loss:  0.76067300637821\n",
      "iteration#:  861  loss:  1.0665484204411382\n",
      "iteration#:  871  loss:  1.6829649606904913\n",
      "iteration#:  881  loss:  1.3007392301795957\n",
      "iteration#:  891  loss:  0.6929914635724697\n",
      "iteration#:  901  loss:  0.6969089290019829\n",
      "iteration#:  911  loss:  1.1475611085170792\n",
      "iteration#:  921  loss:  1.9618977822856054\n",
      "iteration#:  931  loss:  1.5568493007669795\n",
      "iteration#:  941  loss:  1.006148448444883\n",
      "iteration#:  951  loss:  0.7070510959696689\n",
      "iteration#:  961  loss:  1.8429183998828846\n",
      "iteration#:  971  loss:  1.4831035553099225\n",
      "iteration#:  981  loss:  2.5902497341693222\n",
      "iteration#:  991  loss:  0.8919815423557507\n",
      "global best loss:  0.3460531730911972\n",
      "Accuracy: 84.615\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': # training phase of the ANN\n",
    "    no_solution = 100 # number of particles in PSO\n",
    "    no_dim = (INPUT_LAYER * HIDDEN_LAYER) + HIDDEN_LAYER + (HIDDEN_LAYER * OUTPUT_LAYER) + OUTPUT_LAYER # number of dimension for each particle\n",
    "    w_range = (0.0, 1.0) # weight range\n",
    "    lr_range = (0.0, 1.0) # learning rate range\n",
    "    iw_range = (0.9, 0.9)  # inertia weight range\n",
    "    c = (0.5, 0.3)  # c[0] = cognitive factor, c[1] = social factor\n",
    "   \n",
    "    # initialise Swarm and call optimize function with forward pass function\n",
    "    s = Swarm(no_solution, no_dim, w_range, lr_range, iw_range, c)\n",
    "    s.optimize(forward_pass, X, Y, 10, 1000)\n",
    "    W = s.get_best_solution()\n",
    "    Y_pred = predict(X, W)\n",
    "    accuracy = get_accuracy(Y, Y_pred) # calculate the accuracy\n",
    "    print(\"Accuracy: %.3f\"%(accuracy*100))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean squared error =  0.15384615384615385\n",
      "\n",
      "Root mean squared error =  0.3922322702763681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "Y = Y.reshape(13,)\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred)\n",
    "print(\"\\nMean squared error = \", mse)\n",
    "rmse = np.sqrt(mean_squared_error(Y,Y_pred))\n",
    "print(\"\\nRoot mean squared error = \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "irv2 = tf.keras.applications.inception_resnet_v2.InceptionResNetV2()\n",
    "predictions = Dense(1, activation='softmax')(irv2.layers[-1].output)\n",
    "model = Model(inputs=irv2.input, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph\n",
    "X_range = np.linspace(X.min(), X.max(), 3)\n",
    "\n",
    "fig = px.scatter(x=X_range.ravel(), y=Y_pred.ravel(), \n",
    "                 opacity=0.8, color_discrete_sequence=['black'],\n",
    "                 labels=dict(x=\"Annual Rainfall\", y=\"FLOODS indicator where 1=YES and 0=NO\",))\n",
    "\n",
    "fig.update_layout(dict(plot_bgcolor = 'white'))\n",
    "\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgrey', \n",
    "                 zeroline=True, zerolinewidth=1, zerolinecolor='lightgrey', \n",
    "                 showline=True, linewidth=1, linecolor='black')\n",
    "\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgrey', \n",
    "                 zeroline=True, zerolinewidth=1, zerolinecolor='lightgrey', \n",
    "                 showline=True, linewidth=1, linecolor='black')\n",
    "\n",
    "fig.update_layout(title=dict(text=\"PSO model graph\", \n",
    "                             font=dict(color='black')))\n",
    "\n",
    "fig.update_traces(marker=dict(size=7))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
